{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part I. ETL Pipeline for Pre-Processing the Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PLEASE RUN THE FOLLOWING CODE FOR PRE-PROCESSING THE FILES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Python packages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Python packages \n",
    "import pandas as pd, numpy as np\n",
    "import cassandra, re, os, glob, json, csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating list of filepaths to process original event csv data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\harik\\Desktop\\Udacity Data Modeling\\project-1b-project-template.ipynb\n"
     ]
    }
   ],
   "source": [
    "# checking your current working directory\n",
    "print(os.getcwd())\n",
    "\n",
    "# Get your current folder and subfolder event data\n",
    "filepath = os.getcwd() + '\\event_data'\n",
    "# print(filepath)\n",
    "\n",
    "file_path_list = []\n",
    "\n",
    "for root, dirs, files in os.walk(filepath): # for loop to create a list of files and collect each filepath\n",
    "    file_path_list = glob.glob(os.path.join(root,'*')) # join the file path and roots with the subdirectories using glob based on pattern, '*' meaning all files\n",
    "#     print(file_path_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Processing the files to create the data file csv that will be used for Apache Casssandra tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8056\n"
     ]
    }
   ],
   "source": [
    "full_data_rows_list = [] # initiating an empty list of rows that will be generated from each file\n",
    "line_number = 0 # Created this variable to know which line might have an issue in a certain file \n",
    "\n",
    "for f in file_path_list: # for every filepath in the file path list \n",
    "    try:\n",
    "        with open(f, 'r', encoding = 'utf8', newline='') as csvfile: # reading csv file\n",
    "            csvreader = csv.reader(csvfile) # creating a csv reader object \n",
    "            next(csvreader) # Reading the next line in the csv file\n",
    "            \n",
    "            for line in csvreader: # Extracting each data row one by one and append it        \n",
    "                line_number += 1 # Incrementing the line number\n",
    "                #print(line)\n",
    "                full_data_rows_list.append(line) \n",
    "                \n",
    "    except Exception as e:\n",
    "        print(\"Check if there might be an issue with file: {} in line number {} else look at the system error below\".format(f, line_number),\"\\n\")\n",
    "        print(e)\n",
    "            \n",
    "print(len(full_data_rows_list)) # To get total number of rows \n",
    "# print(full_data_rows_list) # Uncomment the code below if you would like to check to see what the list of event data rows will look like\n",
    "\n",
    "# The function register_dialect will creates our own dialect with the name \"myDialect\"\n",
    "# QUOTE_ALL will enable quotes around all fields \n",
    "# skipinitialspace will ignore the spaces right after the delimiter\n",
    "csv.register_dialect('myDialect', quoting=csv.QUOTE_ALL, skipinitialspace=True)\n",
    "\n",
    "# Creating a event_datafile_full csv that will be used to insert data into the apache Cassandra tables with exception handling\n",
    "try:\n",
    "    with open('event_datafile_new.csv', 'w', encoding = 'utf8', newline='') as f:\n",
    "        writer = csv.writer(f, dialect='myDialect') # Using our new dialect to csv writer\n",
    "        writer.writerow(['artist','firstName','gender','itemInSession','lastName','length',\\\n",
    "                    'level','location','sessionId','song','userId']) # Creating columns in the csv in the first row\n",
    "        \n",
    "        for row in full_data_rows_list:\n",
    "            \n",
    "            if (row[0] == ''): #Excluding rows without artist name\n",
    "                continue\n",
    "            \n",
    "            writer.writerow((row[0], row[2], row[3], row[4], row[5], row[6], row[7], row[8], row[12], row[13], row[16]))\n",
    "\n",
    "except Exception as e:\n",
    "    print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6821\n"
     ]
    }
   ],
   "source": [
    "with open('event_datafile_new.csv', 'r', encoding = 'utf8') as f: # check the number of rows in your csv file\n",
    "    print(sum(1 for line in f))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part II. Apache Cassandra coding \n",
    "\n",
    "## The CSV file titled <font color=red>event_datafile_new.csv</font>, located within the Workspace directory contains the following columns: \n",
    "- artist \n",
    "- firstName of user\n",
    "- gender of user\n",
    "- item number in session\n",
    "- last name of user\n",
    "- length of the song\n",
    "- level (paid or free song)\n",
    "- location of the user\n",
    "- sessionId\n",
    "- song title\n",
    "- userId\n",
    "\n",
    "The image below is a screenshot of what the denormalized data should appear like in the <font color=red>**event_datafile_new.csv**</font> after the code above is run:<br>\n",
    "\n",
    "<img src=\"images/image_event_datafile_new.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Begin writing your Apache Cassandra code in the cells below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating a Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection to local host successful and session created\n"
     ]
    }
   ],
   "source": [
    "# Creating a cassandra local connection with exception handling\n",
    "from cassandra.cluster import Cluster\n",
    "\n",
    "try:\n",
    "    cluster = Cluster(['127.0.0.1']) #If you have a locally installed Apache Cassandra instance\n",
    "    session = cluster.connect() # To establish connection and begin executing queries, need a session\n",
    "    print(\"Connection to local host successful and session created\")\n",
    "except Exception as e:\n",
    "    print(f\"Check you connection details and session active or not or check below \\n {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Keyspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key Space created\n"
     ]
    }
   ],
   "source": [
    "# Creating a Keyspace with exception handling \n",
    "try:\n",
    "    create_query = \"\"\"CREATE KEYSPACE IF NOT EXISTS sparkify \n",
    "                    with REPLICATION = \n",
    "                    { 'class' : 'SimpleStrategy', 'replication_factor' : 1 }\n",
    "                \"\"\"\n",
    "    session.execute(create_query)\n",
    "    print(\"Key Space created\")\n",
    "except Exception as e:\n",
    "    print(f\"Key Space creation failed \\n {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set Keyspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key space set successfully\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    session.set_keyspace('sparkify') # Set KEYSPACE to the keyspace specified above, this is similar to USE DataBase in SQL\n",
    "    print(\"Key space set successfully\")\n",
    "except Exception as e:\n",
    "    print(f\"Setting Key space failed \\n {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With Apache Cassandra we model the database tables based on the queries we want to run and creating the tables according to the below queries is our requirement\n",
    "#### 1. Give me the artist, song title and song's length in the music app history that was heard during  sessionId = 338, and itemInSession  = 4\n",
    "        > Based on the above requirement we will need to set primary key sessionId, itemInSession. The create table will need to be in the order of primary keys, cluster keys and other columns that are in the select statment i.e., artist, song, length \n",
    "#### 2. Give me only the following: name of artist, song (sorted by itemInSession) and user (first and last name) for userid = 10, sessionid = 182\n",
    "        > Based on the above requirement the create table will need to be in the order of composite primary keys (userId, sessionId), and cluster key itemInSession and then remaining columns in the select statement in proposed order i.e., artist, song, firstname, lastname. The order of select, insert and create will be same. This is the requirement of Cassandra\n",
    "#### 3. Give me every user name (first and last) in my music app history who listened to the song 'All Hands Against His Own'\n",
    "        > This query also follows a similar structure as above. Song would be primary key, but we are considering a scenario where multiple users will be accessing the same song and this will result in duplicates, hence we will create a composite primary key (song, userId). The create table will be in the order song, userId, firstname, lastname. Insert will also follow the same order\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select statements for above requirement\n",
    "select_query1_table1 = \"select artist, song, length from music_app_history_by_session_item where sessionId = 338 and itemInSession = 4\"\n",
    "select_query1_table2 = \"select artist, song, firstname, lastname from music_app_history_by_user_session where userId = 10 and sessionId = 182 order by itemInSession Asc \"\n",
    "select_query1_table3 = \"select firstname, lastname from music_app_history_by_song where song = 'All Hands Against His Own'\"                  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we create tables and insert data from \"event_datafile_new\" to run the above queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "music_app_history_by_session_item table created\n",
      "music_app_history_by_session_item insert completed\n"
     ]
    }
   ],
   "source": [
    "# Query 1:  Give me the artist, song title and song's length in the music app history that was heard during\n",
    "create_table1 = \"CREATE TABLE IF NOT EXISTS music_app_history_by_session_item (sessionId INT, itemInSession INT, artist TEXT, song TEXT, length FLOAT, PRIMARY KEY (sessionId, itemInSession))\"\n",
    "\n",
    "try:\n",
    "    session.execute(create_table1)\n",
    "    print(\"music_app_history_by_session_item table created\")\n",
    "except Exception as e:\n",
    "    print(f\"music_app_history_by_session_item table Creation Failed \\n {e}\")        \n",
    "    \n",
    "file = 'event_datafile_new.csv' # Input file name\n",
    "\n",
    "# Insert code for music_app_history_by_session_item\n",
    "try:\n",
    "    with open(file, encoding = 'utf8') as f:\n",
    "        csvreader = csv.reader(f)\n",
    "        next(csvreader) # skip header\n",
    "        \n",
    "        for line in csvreader:\n",
    "            query = \"INSERT INTO music_app_history_by_session_item (sessionId, itemInSession,  artist, song, length)\"\n",
    "            query = query + \"VALUES (%s, %s, %s, %s, %s)\"\n",
    "            session.execute(query, (int(line[8]), int(line[3]), line[0], line[9], float(line[5])))\n",
    "    print(\"music_app_history_by_session_item insert completed\")\n",
    "except Exception as e:\n",
    "    print(f\"music_app_history_by_session_item insert failed \\n {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "music_app_history_by_user_session table created\n",
      "music_app_history_by_user_session insert completed\n"
     ]
    }
   ],
   "source": [
    "# Query 2: Give me only the following: name of artist, song (sorted by itemInSession) and user (first and last name)\n",
    "create_table2 = \"CREATE TABLE IF NOT EXISTS music_app_history_by_user_session (userId INT,sessionId INT,itemInSession INT,artist TEXT,song TEXT,firstName TEXT,lastName TEXT,PRIMARY KEY ((userId, sessionid), itemInSession)) \"\n",
    "try:\n",
    "    session.execute(create_table2)\n",
    "    print(\"music_app_history_by_user_session table created\")\n",
    "except Exception as e:\n",
    "    print(f\"music_app_history_by_user_session table Creation Failed \\n {e}\") \n",
    "    \n",
    "# Insert code for music_app_history_by_user_session\n",
    "try:\n",
    "    with open(file, encoding = 'utf8') as f:\n",
    "        csvreader = csv.reader(f)\n",
    "        next(csvreader) # skip header\n",
    "        \n",
    "        for line in csvreader:\n",
    "            query = \"INSERT INTO music_app_history_by_user_session (userId,sessionId,itemInSession,artist,song,firstName,lastName)\"\n",
    "            query = query + \"VALUES (%s, %s, %s, %s, %s, %s, %s)\"\n",
    "            session.execute(query, (int(line[10]), int(line[8]), int(line[3]), line[0], line[9], line[1], line[4]))\n",
    "    print(\"music_app_history_by_user_session insert completed\")\n",
    "except Exception as e:\n",
    "    print(f\"music_app_history_by_user_session insert failed \\n {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "music_app_history_by_song table created\n",
      "music_app_history_by_song insert completed\n"
     ]
    }
   ],
   "source": [
    "# Query 3: Give me every user name (first and last) in my music app history who listened to the song 'All Hands Against His Own'\n",
    "create_table3 = \"CREATE TABLE IF NOT EXISTS music_app_history_by_song (song TEXT, userId INT, firstname TEXT, lastname TEXT, PRIMARY KEY((song), userId))\"\n",
    "try:\n",
    "    session.execute(create_table3)\n",
    "    print(\"music_app_history_by_song table created\")\n",
    "except Exception as e:\n",
    "    print(f\"music_app_history_by_song table Creation Failed \\n {e}\") \n",
    "\n",
    "    \n",
    "# Insert code for music_app_history_by_song\n",
    "try:\n",
    "    with open(file, encoding = 'utf8') as f:\n",
    "        csvreader = csv.reader(f)\n",
    "        next(csvreader) # skip header\n",
    "        \n",
    "        for line in csvreader:\n",
    "            query = \"INSERT INTO music_app_history_by_song (song, userId, firstname, lastname)\"\n",
    "            query = query + \"VALUES (%s, %s ,%s, %s)\"\n",
    "            session.execute(query, (line[9], int(line[10]),line[1], line[4]))\n",
    "    print(\"music_app_history_by_song insert completed\")\n",
    "except Exception as e:\n",
    "    print(f\"music_app_history_by_song insert failed \\n {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Doing a SELECT to verify that the data have been inserted into each table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row(artist='Faithless', song='Music Matters (Mark Knight Dub)', length=495.30731201171875)\n"
     ]
    }
   ],
   "source": [
    "# Select for music_app_history_by_song\n",
    "try:\n",
    "    rows = session.execute(select_query1_table1)\n",
    "except Exception as e:\n",
    "    print(f\"Select for music_app_history_by_song Failed \\n {e}\")\n",
    "    \n",
    "for row in rows:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row(artist='Down To The Bone', song=\"Keep On Keepin' On\", firstname='Sylvie', lastname='Cruz')\n",
      "Row(artist='Three Drives', song='Greece 2000', firstname='Sylvie', lastname='Cruz')\n",
      "Row(artist='Sebastien Tellier', song='Kilometer', firstname='Sylvie', lastname='Cruz')\n",
      "Row(artist='Lonnie Gordon', song='Catch You Baby (Steve Pitron & Max Sanna Radio Edit)', firstname='Sylvie', lastname='Cruz')\n"
     ]
    }
   ],
   "source": [
    "# Select for music_app_history_by_user_session\n",
    "try:\n",
    "    rows = session.execute(select_query1_table2)\n",
    "except Exception as e:\n",
    "    print(f\"Select for music_app_history_by_user_session Failed \\n {e}\")\n",
    "    \n",
    "for row in rows:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row(firstname='Jacqueline', lastname='Lynch')\n",
      "Row(firstname='Tegan', lastname='Levine')\n",
      "Row(firstname='Sara', lastname='Johnson')\n"
     ]
    }
   ],
   "source": [
    "# Select for music_app_history_by_song\n",
    "try:\n",
    "    rows = session.execute(select_query1_table3)\n",
    "except Exception as e:\n",
    "    print(f\"Select for music_app_history_by_song Failed \\n {e}\")\n",
    "    \n",
    "for row in rows:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop the tables before closing out the sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drop completed\n"
     ]
    }
   ],
   "source": [
    "## Drop the table before closing out the sessions\n",
    "drop1 = \"DROP TABLE IF EXISTS music_app_history_by_session_item\"\n",
    "drop2 = \"DROP TABLE IF EXISTS music_app_history_by_user_session\"\n",
    "drop3 = \"DROP TABLE IF EXISTS music_app_history_by_song\"\n",
    "try:\n",
    "    session.execute(drop1)\n",
    "    session.execute(drop2)\n",
    "    session.execute(drop3)\n",
    "    print(\"Drop completed\")\n",
    "except Exception as e:\n",
    "    print(f\"Drop failed \\n {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Close the session and cluster connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.shutdown()\n",
    "cluster.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
